# JSX-like Template Parser

A lightweight, high-performance, two-pass tokenizer and parser for processing JSX-like template strings with embedded JavaScript expressions.

This library is designed for speed and a small bundle size, making it ideal for template engines, static site generators, or any tool that needs to deconstruct a string into a structured Abstract Syntax Tree (AST). It uses a state-machine-based tokenizer and a single-pass, stack-based parser.

## Features

-   **High-Performance Tokenizer**: Uses `charCodeAt` and a state machine for fast, efficient tokenization.
-   **Robust Parser**: Builds a complete Abstract Syntax Tree (AST) in a single pass over the tokens.
-   **Expression Support**: Natively handles embedded expressions (e.g., `${...}`).
-   **Attribute Variety**: Parses boolean attributes, static key/value attributes, and attributes with embedded expressions.
-   **Special Element Handling**: Configurable support for `void` elements (e.g., `<input>`) and `raw text` elements (e.g., `<script>`, `<style>`).
-   **Whitespace Control**: Intelligently removes superfluous whitespace between elements while preserving meaningful text nodes.
-   **Zero Dependencies**: Written in pure TypeScript with no external libraries.

## Installation

```bash
npm install parse-jsx
```

## Usage

The library exports two main functions: `tokenize` and `parse`. You typically use them together to convert a template string into an AST.

```typescript
import { tokenize, parse } from './your-parser-library';

// 1. Define your template string with expressions.
// NOTE: This example uses a tagged template literal, which is what the
// tokenizer expects. The values from expressions are not used directly,
// but their positions are captured.
const template = (strings, ...values) => ({ strings, values });
const myTemplate = template`<div class="container ${'dynamicClass'}">
  <h1>Hello, World!</h1>
  <input type="text" disabled>
  <p>This is a template literal.</p>
</div>`;

// 2. Define which elements are considered "void" (self-closing).
const voidElements = new Set(['input', 'br', 'hr', 'img']);

// 3. Define which elements contain raw text that should not be parsed.
const rawTextElements = new Set(['script', 'style']);

// 4. Tokenize the input string.
const tokens = tokenize(myTemplate.strings, rawTextElements);

// 5. Parse the tokens into an AST.
const ast = parse(tokens, voidElements);

// 6. Log the result.
console.log(JSON.stringify(ast, null, 2));
```

### The AST Structure

The `parse` function returns a `RootNode` which contains an array of child nodes. The structure is designed to be simple and easy to traverse.

**Example AST for `<p>Hello, ${name}!</p>`:**

```json
{
  "type": 0, // ROOT_NODE
  "children": [
    {
      "type": 1, // ELEMENT_NODE
      "name": "p",
      "props": [],
      "children": [
        {
          "type": 2, // TEXT_NODE
          "value": "Hello, "
        },
        {
          "type": 3, // EXPRESSION_NODE
          "value": 0 // Index of the expression in the original template literal
        },
        {
          "type": 2, // TEXT_NODE
          "value": "!"
        }
      ]
    }
  ]
}
```

## How It Works

The library operates in two distinct phases for maximum efficiency and separation of concerns.

1.  **Tokenization**: The `tokenize` function scans the input string and breaks it down into a flat array of `Token` objects. It uses a finite state machine to switch between different contexts (text, tags, attributes) and `charCodeAt` for fast character analysis. This avoids the overhead of regular expressions.

2.  **Parsing**: The `parse` function consumes the array of tokens and builds the hierarchical AST. It uses a stack to keep track of the current parent element, allowing it to correctly handle nested structures. It processes the tokens in a single pass, creating element nodes, text nodes, and attaching props as it goes.

## API Reference

### `tokenize(strings, rawTextElements)`

-   **`strings`**: `TemplateStringsArray`. The array of strings from a tagged template literal.
-   **`rawTextElements`**: `Set<string>`. A set of lowercase tag names that should be treated as containing raw, un-parsed text (e.g., `script`, `style`).
-   **Returns**: `Token[]`. An array of token objects.

### `parse(tokens, voidElements)`

-   **`tokens`**: `Token[]`. The array of tokens generated by the `tokenize` function.
-   **`voidElements`**: `Set<string>`. A set of lowercase tag names that are self-closing and cannot have children (e.g., `input`, `img`).
-   **Returns**: `RootNode`. The root of the generated Abstract Syntax Tree.

### Node and Prop Types

The parser generates different types of nodes and properties, identified by numeric constants for performance and small bundle size.

**Node Types:**

-   `ROOT_NODE` (0): The top-level node.
-   `ELEMENT_NODE` (1): An HTML-like element with a tag name, props, and children.
-   `TEXT_NODE` (2): A plain text node.
-   `EXPRESSION_NODE` (3): A placeholder for a dynamic expression.

**Prop Types:**

-   `BOOLEAN_PROP` (0): A valueless attribute (e.g., `disabled`).
-   `STATIC_PROP` (1): An attribute with a static string value (e.g., `class="container"`).
-   `EXPRESSION_PROP` (2): An attribute whose value is a single expression (e.g., `id=${postId}`).
-   `SPREAD_PROP` (3): A spread expression in the props list (e.g., `<div ${props} />`).
-   `MIXED_PROP` (4): An attribute with a mix of static text and expressions (e.g., `class="base ${extra}"`).

## Contributing

Contributions are welcome! If you find a bug or have a suggestion for improvement, please open an issue or submit a pull request.

## License

[MIT](LICENSE)